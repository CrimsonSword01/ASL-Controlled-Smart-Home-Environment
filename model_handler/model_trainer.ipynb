{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CONTRIBUTORS:\n",
    "    Paul Durham\n",
    "FILE CONTENT DESCRIPTION:\n",
    "\tThe file main.py leverages functionality from the various components of SLISH in order to produce a working, efficient \n",
    "\tsoftware. The user interface design and functionalities are implemented utilizing the tkinter library for its development.\n",
    "\tAs previously mentioned, the methods from every component of SLISH are used logically in order for SLISH to act accordingly\n",
    "\tbased on the recevied input. \n",
    "\t\n",
    "\tSpecific methods and logic leveraged from the camera component in this file include the system \n",
    "\t\"cool down\" period and retrieving the external input for use by the rest of the system.\n",
    "\t\n",
    "\tThe classifier comoponent's methods are used frequently throughout the latter contents of this file.\n",
    "    Based on the classifications made by the classifier component, logic in main.py determines whether enough\n",
    "\tframes have been classified to make an accurate gesture prediction and, if so, whether to execute a command \n",
    "\tbased on the received input. Specifically, this ensures that at least 6 frames were analyzed before a prediction\n",
    "\tis made, ensures that commands are only recognized in a format valid to SLISH (letter -> number) and handles\n",
    "\tinvalid or unrecognized input without affecting system performance. \n",
    "\tLast, methods from the socket class are utilized to control the web sockets that correspond to the command received.\n",
    "\tThe actions that are executed are clearly displayed within the contents of the user interface. \n",
    "REQUIREMENTS ADDRESSED:\n",
    "    FR.2, FR.2.1, FR 2.1.1, FR.2.1.2, FR.2.1.3, FR2.2, FR.2.3,\n",
    "\tNFR.2, NFR.4, NFR.5, NFR.6, NFR.7, NFR.8, NFR.9\n",
    "\tEIR.1, EIR.2\n",
    "LICENSE INFORMATION:\n",
    "    Copyright (c) 2019, CSC 450 Group 1\n",
    "    All rights reserved.\n",
    "    Redistribution and use in source and binary forms, with or without modification, are permitted provided that the\n",
    "    following conditions are met:\n",
    "        * Redistributions of source code must retain the above copyright notice, this list of conditions and the\n",
    "          following disclaimer.\n",
    "        * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and\n",
    "          the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "        * Neither the name of the CSC 450 Group 4 nor the names of its contributors may be used to endorse or\n",
    "          promote products derived from this software without specific prior written permission.\n",
    "    THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES,\n",
    "    INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "    DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,\n",
    "    OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n",
    "    DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,\n",
    "    STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE,\n",
    "    EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "\n",
    "# Global Variables init\n",
    "input_size = 0\n",
    "device = 'cpu'\n",
    "num_classes = 6\n",
    "\n",
    "## This function will take a model and train the model.\n",
    "def train(model):\n",
    "\n",
    "    model_name = \"alexnet\"\n",
    "\n",
    "    ## This is the batch size for the training. This can be changed based on the amount of ram your system has.\n",
    "    batch_size = 8\n",
    "\n",
    "    ## The number of epochs to train for\n",
    "    num_epochs = 15\n",
    "\n",
    "    ## feature_extract = True = The reshaped layer params will be updated \n",
    "    ## feature_etract = False = Finetune the whole model\n",
    "    feature_extract = True\n",
    "\n",
    "    ## Init the model incase we are not bringing a model in\n",
    "    model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "    ## A transformer that will reshape/change the incoming images\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            ## This will add some randomization to the images\n",
    "            #transforms.RandomAffine(degrees=10, translate=[0,.3], scale=[.001,.3], shear=None, resample=False, fillcolor=0),\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.Grayscale(num_output_channels=3),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.Grayscale(num_output_channels=3),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    ## Create data loaders for the images\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "    ## Check if a gpu is available for calculations\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    ## Send the model to the device (cpu/gpu)\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    ## Gets the parameters from the model to be trained \n",
    "    params_to_update = model_ft.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "\n",
    "    optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "    ## sets the lossfunction  crossentropyloss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    ## begin training and evaluation\n",
    "    if model != None:\n",
    "        print(\"Trained the loaded model\")\n",
    "        model_ft, hist = train_model(model, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "    else:\n",
    "        print(\"Trained a new model\")\n",
    "        model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))    \n",
    "    ## Saves model\n",
    "    torch.save(model_ft.state_dict(),'model.pt')\n",
    "\n",
    "## Training function\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n",
    "\n",
    "## Sets parameters that require grad\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=False):\n",
    "    model_ft = None\n",
    "    \n",
    "    ## This init function is only able to init alexnet model.\n",
    "    if odel_name == \"alexnet\":\n",
    "\n",
    "        model_ft = torch.hub.load('pytorch/vision:v0.5.0', 'alexnet', pretrained=True)\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    return model_ft, input_size\n",
    "\n",
    "## Loads model\n",
    "## Change model.pt to the model name you wish to load\n",
    "def load_model():\n",
    "    return torch.load('../model_handler/model.pt')\n",
    "    \n",
    "\n",
    "\n",
    "model = None\n",
    "\n",
    "try:\n",
    "    model = load_model()\n",
    "except Exception:\n",
    "    print(\"Creating new model\")\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
